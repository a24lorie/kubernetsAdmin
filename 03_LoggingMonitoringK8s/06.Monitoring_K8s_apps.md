### Introduction

There are many metrics that you may want to keep track of in Kubernetes: available node CPU/Memory, number of running Pods vs. desired Pods for Deployments, errors and warnings, etc. There are several built-in mechanisms available to make monitoring and debugging applications easier. You can also leverage purpose-built monitoring systems that run in Pods. Kubernetes has their own basic monitoring solution called  [Metrics Server](https://github.com/kubernetes-incubator/metrics-server). You will use Metrics Server later in this Lab Step. You can also use more complete metrics pipelines, such as  [Prometheus](https://prometheus.io/), but that is beyond the scope of this Lab.

### Instructions

1. Use the  `get`  command to ensure all Pods have all containers running:
```
kubectl get pods --all-namespaces
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid0-3a6a5b68-6a86-4dd5-8cc6-84fdeab29289.png)

The **READY** column separates the number of containers that are ready and the number of containers in a Pod by a slash. You can quickly get a view off all the Pods in the cluster by adding the  `--all-namespaces`  option to  `get`. Similarly for any other Resource type, you can use get to quickly get a view of those Resources. For example, the output for Deployments lists the desired and actual number of Pods that are in each Deployment.

To get more information you can use some commands you have used extensively in this Lab:

-   `describe`  which includes information about the resource itself as well as related resources and events
-   `logs` for diagnosing any failures related to Pods and containers

The  `get`  command can also be used to view complete configuration details by adding instructing the command to output in YAML format (`-o yaml`). This can help you diagnose any suspected configuration issues.

2. List all the events in the logs namespace:
```
kubectl get events -n logs
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid1-879a0169-5df3-4f62-a342-6e48450deaeb.png)

You can retrieve events for individual resources by using the describe command, but the get events command allows you to see all events in sequence. Events are namespaced so you can limit your search by Namespace. To get additional information, you can instruct  `get`  to output in wide format (`-o wide`).

3. Enter the following command to see how to use the top command to monitor node and Pod resource utilization:
```
kubectl top
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid0-63821ce1-28a6-4dbb-9e62-a805bb299bc4.png)

The kubectl top command is in the same spirit as the `top`  command for Unix-based operating systems. As the output states, the  `top`  command depends on a properly configured system for collecting the usage information. **Heapster**  is a deprecated tool for collecting metrics. Metrics Server is the supported tool that Kubernetes provides. Metrics Server implements the Kubernetes metrics API. Other metric pipelines can also implement the metrics API to work with  `top`  and provide additional functionality, e.g. Prometheus, however they are outside of the scope of this Lab.

Metrics Server is not installed so top will not work if you try to use it now.

4. Download the Metrics Server manifest files and create the associated Resources:
```
wget -O /tmp/metrics-server.zip https://github.com/cloudacademy/metrics-server/archive/master.zip  
sudo apt install unzip  
unzip -q -d /tmp /tmp/metrics-server.zip  
kubectl create -f /tmp/metrics-server-master/deploy/1.8+/
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid1-ae92a8a9-7733-4d08-ad6c-37f73ddbb345.png)

Amongst the  **role**  and  **rolebinding** resources that give Metrics Server the permisison it need to collect metrics, the metrics API (**v1beta1.metrics.k8s.io**) is registered. A deployment and service for accessing Metrics Server are also created. You are now gathering node and Pod resource utilization metrics with Metrics Server.

5. Use  `top`  to view resource utilization metrics for the cluster's nodes:
```
kubectl top node
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid2-d17bc20d-5659-4043-b659-47aac09a0df5.png)

The output displays  **CPU**  usage in **cores**  and **%**. The master and nodes both have 2 CPU cores available. The **CPU(cores)**  column would have a maximum value of 2000m (2000 milliCPU cores = 2 CPU cores). The  **CPU** metrics indicate that the cluster is not under CPU pressure. The **MEMORY**  columns indicate that there is less than 50% memory available on the nodes. That is not a problem if workloads on the cluster are stable. As new Pods are added you should monitor the memory pressure. You should also set CPU and memory limits and requests in your Pod containers to avoid an unexpected degradation in performance. Issue `kubectl explain pod.spec.containers.resources`  for more information.

_Warning_: It can take a minute for the first metrics to become available. Re-issue the command after a minute if you receive the error  **metrics not available yet**.

6. Use `top` to view resource utilization metrics for the Pod's in the logs Namespace:
```
kubectl top pods -n logs
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid3-348c83c2-7a39-4b98-9fab-e22bb4d07e4b.png)

From this view, you can see if there are any indications that a Pod is using an unexpected amount of resources.

7. Display the resource utilization of individual containers:
```
kubectl top pod -n logs --containers
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid4-2e2ff965-a74f-44b3-9d62-f27e12f5ecdd.png)

The --containers option allows you to understand the resource utilization at a finer granularity.

8. Use a label selector to show only resource utilizaiton for Pods with a  `test`  label:
```
kubectl top pod -n logs --containers -l test
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid0-bd632927-758d-4340-bd94-a183157f37a8.png)

Label selectors make it easy to focus your search as long as you have a well-defined labeling strategy.

### Summary

In this Lab Step, you used several  `kubectl`  commands that allow you to monitor your Kubernetes applications. You also installed Metrics Server to implement the metrics API that the  `top`  command depends on.

If you have more time in your Lab Session, try issuing more logging, monitoring, and debugging types of commands. Try to inspect Pods, Deployments, and Services in the  `kube-system`  Namespace. For example:

-   See if you can identify which container uses the most CPU or memory in the  `kube-system`  namespace.
-   See if you can get the last 10 lines out of the etcd Pod's /etc/mtab file.
