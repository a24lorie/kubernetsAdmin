### Introduction

The state information of a Kubernetes cluster is stored in etcd. You can back up a Kubernetes cluster and restore it to an earlier state by using the snapshot and restore functionality of etcd. You will explore this functionality in this Lab Step. You will use a command-line client named  [etcdctl](https://github.com/coreos/etcd/tree/master/etcdctl) to interact with the Kubernetes ectd key-value store. Rather than install etcdctl on the host machine, which is a viable option, you will use pods and containers to perform the backup and restore operations.

Although not a focus of this Lab Step, in practice you should also back up the cluster's certificate authority key (/etc/kubernetes/pki/ca.key) and certificate (/etc/kubernetes/pki/ca.crt). You should do that after the master is first initialized with  `kubeadm init`.

### Instructions

1. Create a deployment of the Nginx application with two replicas:

```
kubectl create deployment nginx --image=nginx  
kubectl scale deployment nginx --replicas=2
```

![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid0-e0a382db-6612-4507-8b1c-5cb4bb324b4f.png)

The deployment and the following service are simply created so that you can confirm they exist after performing a cluster restore operation at the end of the Lab Step.

2. Expose the deployment using a ClusterIP service:

```
kubectl expose deployment nginx --name=clusterip --port=80 --target-port=80 --name=web
```

![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid1-b4d48a8c-03fd-44d7-8e9c-2b3e7f4a6993.png)

3. Send a HTTP request to the web service:

```
# Get the Cluster IP of the service  
service_ip=$(kubectl get service web -o jsonpath='{.spec.clusterIP}')  
# Use curl to send an HTTP request to the service  
curl $service_ip
```

![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid2-cfdb9c2e-20a8-4200-8971-d863d1b8a271.png)

The Nginx server response verifies that everything is working as expected.

4. Create a management namespace:
```
kubectl create namespace management 
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid0-4ebd6a09-952e-4eec-858b-38bcca5cba01.png)

5. Create a job that creates a pod, and issues the  `etcdctl snapshot save`  command to back up the cluster:

```
cat <<EOF | kubectl create -f -  
apiVersion: batch/v1  
kind: Job  
metadata:  
  name: backup  
  namespace: management  
spec:  
  template:  
    spec:  
      containers:  
      # Use etcdctl snapshot save to create a snapshot in the /snapshot directory   
      - command:  
        - /bin/sh   
        args:  
        - -ec  
        - etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key snapshot save /snapshots/backup.db  
        # The same image used by the etcd pod  
        image: k8s.gcr.io/etcd-amd64:3.1.12  
        name: etcdctl  
        env:  
        # Set the etcdctl API version to 3 (to match the version of etcd installed by kubeadm)  
        - name: ETCDCTL_API  
          value: '3'  
        volumeMounts:  
        - mountPath: /etc/kubernetes/pki/etcd  
          name: etcd-certs  
          readOnly: true  
        - mountPath: /snapshots  
          name: snapshots  
      # Use the host network where the etcd port is accessible (etcd pod uses host network)  
      # This allows the etcdctl to connect to etcd that is listening on the host network  
      hostNetwork: true  
      affinity:  
        # Use node affinity to schedule the pod on the master (where the etcd pod is)  
        nodeAffinity:  
          requiredDuringSchedulingIgnoredDuringExecution:  
            nodeSelectorTerms:  
            - matchExpressions:  
              - key: node-role.kubernetes.io/master  
                operator: Exists  
      restartPolicy: OnFailure  
      tolerations:  
      # tolerate the master's NoSchedule taint to allow scheduling on the master  
      - effect: NoSchedule  
        operator: Exists  
      volumes:  
      # Volume storing the etcd PKI keys and certificates  
      - hostPath:  
          path: /etc/kubernetes/pki/etcd  
          type: DirectoryOrCreate  
        name: etcd-certs  
      # A volume to store the backup snapshot  
      - hostPath:  
          path: /snapshots  
          type: DirectoryOrCreate  
        name: snapshots  
EOF
```
You could also create a [CronJob Kubernetes resource](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/) instead of a one-off  `Job`  to periodically perform the backup operation. A  `Job`  is sufficient for this Lab. Read through the  `Job`  manifest, and use the comments to help understand what it does.

The  `etcdctl` command (see `spec.template.spec.containers.args`) requires the certificate authority certificate, a client key, and a client certificate to encrypt the etcd traffic.  `kubeadm` configures etcd to listen to HTTPS only as a security best practice. The  `snapshot save`  command creates a snapshot of the entire key-value store at the given location (`/snapshots/backup.db`).

6. List the contents of the /snapshots directory:
```
ls /snapshots
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid0-cfb057a7-b13b-446e-94a4-37ab3d509cc4.png)

The etcd snapshot saved by the pod is present. You will now cause the master to fail and remove the data files of the etcd key-value store to simulate a substantial cluster failure.

7. Stop the master's kubelet:
```
sudo systemctl stop kubelet.service
```
The kubelet will automatically try to restart the etcd pod if it detects that it has been deleted. You need to stop the kubelet to prevent this.

8. Delete the etcd containers in Docker that are created by the Kubernetes etcd pod:
```
sudo docker ps | grep etcd | cut -d' ' -f1 | xargs sudo docker rm -f
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid0-0b6c6aa6-6061-4ce1-82d2-75289c2422f5.png)

The container IDs of the deleted etcd containers are displayed.

9. Delete the etcd data files persisted to disk:
```
sudo rm -rf /var/lib/etcd/*
```
The etcd pod mounts /var/lib/etcd to persist its data to disk.

10. Use a Docker container to restore the /var/lib/etcd data from the backup snapshot:
```
sudo docker run --rm \
    -v '/snapshots:/snapshots' \
    -v '/var/lib/etcd:/var/lib/etcd' \
    -e ETCDCTL_API=3 \
    'k8s.gcr.io/etcd-amd64:3.1.12' \
    /bin/sh -c "etcdctl snapshot restore '/snapshots/backup.db' && mv /default.etcd/member /var/lib/etcd"
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid3-85f683ba-e7c6-4b17-8b5a-d27a014de691.png)

You need to directly use Docker instead of creating a pod in Kubernetes because Kubernetes will not function with the kubelet and etcd offline. The kubelet will recreate the etcd pod from the static pod manifest in /etc/kubernetes/manifests/etcd.yaml. The  `etcdctl snapshot restore`  command performs the restore operation.

11. Start the kubelet:
```
sudo systemctl start kubelet
```
The kubelet automatically recreates the missing etcd pod containers. The pod will use the restored data files created from the backup, and Kubernetes will have a restored view of the cluster.

12. Confirm the Nginx pods are running:
```
kubectl get pods
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid1-f5c42751-36cf-44be-8a70-b94fd7b0c6f9.png)

13. Confirm the web service works:
```
service_ip=$(kubectl get service web -o jsonpath='{.spec.clusterIP}')  
curl $service_ip
```
![alt](https://assets.cloudacademy.com/bakery/media/uploads/blobid2-d56e80b4-6b19-4111-9efd-739bddab3ddf.png)

### Summary

In this Lab Step, you performed backup and restore operations of Kubernetes underlying etcd data store.
